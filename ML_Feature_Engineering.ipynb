{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Assignment Questions"
      ],
      "metadata": {
        "id": "I49E4-n997bE"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8a1c157"
      },
      "source": [
        "1. What is a parameter?\n",
        "\n",
        "- A parameter is an internal variable learned by a model during training (e.g., weights, biases in neural networks).\n",
        "\n",
        "2. What is correlation?\n",
        "\n",
        "- Correlation measures the statistical relationship between two variables — how they move together.\n",
        "Common metric: Pearson correlation coefficient r (range -1 to +1).\n",
        "\n",
        "3. What does negative correlation mean?\n",
        "\n",
        "- Negative correlation means when one variable increases, the other tends to decrease.\n",
        "Example: r = -0.8 indicates strong inverse relationship.\n",
        "\n",
        "4. Define Machine Learning. What are the main components in Machine Learning?\n",
        "\n",
        "- ML: field that builds algorithms that learn patterns from data to make predictions or decisions.\n",
        "Main components: Data (features/labels), Model (algorithm), Loss/Objective function, Optimizer (training procedure), Evaluation metrics, Deployment pipeline.\n",
        "\n",
        "5. How does loss value help in determining whether the model is good or not?\n",
        "- Loss quantifies model errors.\n",
        "Lower loss → better fit.\n",
        "\n",
        "6. What are continuous and categorical variables?\n",
        "\n",
        "- Continuous: numeric variables with infinite/real values (e.g., height, price).\n",
        "Categorical: discrete groups/labels (e.g., color: red/blue/green).\n",
        "\n",
        "7. How do we handle categorical variables in Machine Learning? What are the common techniques?\n",
        "\n",
        "- To handle categorical variables, we must first identify them, then convert them into a numerical format that machine learning algorithms can understand using various encoding techniques, such as One-Hot Encoding, Label Encoding, Target Encoding, and Frequency Encoding\n",
        "Techniques:\n",
        "Label Encoding,\n",
        "One-Hot Encoding,\n",
        "Ordinal Encoding\n",
        "\n",
        "8. What do you mean by training and testing a dataset?\n",
        "\n",
        "- Training: fit the model on a subset (learn parameters).\n",
        "Testing: evaluate final model performance on unseen data to estimate generalization.\n",
        "\n",
        "9. What is sklearn.preprocessing?\n",
        "\n",
        "- A module in Scikit-learn with tools for scaling, encoding, normalization, etc.\n",
        "\n",
        "10. What is a Test set?\n",
        "\n",
        "- A dataset held out (not used in training or hyperparameter tuning) used only to evaluate final model performance.\n",
        "\n",
        "11. How do we split data for model fitting (training and testing) in Python?\n",
        "\n",
        "- Use train_test_split from sklearn.model_selection. Example: X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42).\n",
        "\n",
        "12. How do you approach a Machine Learning problem?\n",
        "\n",
        "- Steps: understand problem & metric → collect data → EDA → preprocessing/feature engineering → split data → choose model(s) → train → validate/tune → evaluate on test → deploy & monitor.\n",
        "\n",
        "13. Why do we have to perform EDA before fitting a model to the data?\n",
        "\n",
        "- EDA reveals data quality, distributions, outliers, missing values, correlations, target imbalance — informs preprocessing and feature engineering decisions and prevents garbage-in→garbage-out.\n",
        "\n",
        "14. What is correlation?\n",
        "\n",
        "- (Repeat) Measure of linear relationship between variables; Pearson r commonly used.\n",
        "\n",
        "15. What does negative correlation mean?\n",
        "\n",
        "- (Repeat) As one variable increases the other decreases; negative r.\n",
        "\n",
        "16. How can you find correlation between variables in Python?\n",
        "\n",
        "- Use pandas.DataFrame.corr() for Pearson correlations.\n",
        "Use seaborn.heatmap(df.corr()) to visualize.\n",
        "\n",
        "17. What is causation? Explain difference between correlation and causation with an example.\n",
        "\n",
        "- Causation: one variable directly affects another.\n",
        "Difference: correlation ≠ causation. Correlation is association; causation implies effect.\n",
        "Example: ice cream sales and drowning incidents correlate (both rise in summer) but ice cream does not cause drownings — a confounder (temperature) causes both.\n",
        "\n",
        "18. What is an Optimizer? What are different types of optimizers? Explain each with an example.\n",
        "\n",
        "- Optimizer updates model parameters to reduce loss.\n",
        "Types:\n",
        "SGD: updates with small steps.\n",
        "Momentum: adds previous gradients for faster convergence.\n",
        "RMSProp: adjusts learning rate based on recent gradients.\n",
        "Adam: combines momentum + RMSProp (most common).\n",
        "\n",
        "19. What is sklearn.linear_model ?\n",
        "\n",
        "- A scikit-learn module that contains linear models: LinearRegression, LogisticRegression, Ridge, Lasso, ElasticNet, SGDRegressor, etc.\n",
        "\n",
        "20. What does model.fit() do? What arguments must be given?\n",
        "\n",
        "- fit() trains the model by learning parameters from data.\n",
        "Typical args: X_train (features), y_train (labels). Some models accept sample weights or additional hyperparams.\n",
        "\n",
        "21. What does model.predict() do? What arguments must be given?\n",
        "\n",
        "- Generates predictions on new/unseen data.\n",
        "Arguments: X_test.\n",
        "\n",
        "22. What are continuous and categorical variables?\n",
        "\n",
        "- (Repeat) Continuous = numeric range; Categorical = discrete classes/labels.\n",
        "\n",
        "23. What is feature scaling? How does it help in Machine Learning?\n",
        "\n",
        "- Feature scaling is the process of transforming features (variables) in a dataset to a common scale or range, such as normalizing them to 0-1 or standardizing them to a mean of 0 and a standard deviation of 1.\n",
        "This technique helps machine learning algorithms perform better by preventing features with larger ranges from disproportionately influencing the model, ensuring all features contribute equally.\n",
        "24. How do we perform scaling in Python?\n",
        "\n",
        "- Use sklearn.preprocessing scalers:\n",
        "StandardScaler() (zero mean, unit variance),\n",
        "MinMaxScaler() (scale to [0,1]),\n",
        "RobustScaler() (uses median & IQR, robust to outliers).\n",
        "Fit scaler on training set (scaler.fit(X_train)) and transform train/test (scaler.transform()).\n",
        "\n",
        "25. What is sklearn.preprocessing?\n",
        "\n",
        "- The sklearn. preprocessing package provides several common utility functions and transformer classes to change raw feature vectors into a representation that is more suitable for the downstream estimators.\n",
        "\n",
        "26. How do we split data for model fitting (training and testing) in Python?\n",
        "\n",
        "- (Repeat) Use train_test_split or StratifiedKFold/KFold for cross-validation. For time series use TimeSeriesSplit or hold-out by time.\n",
        "\n",
        "27. Explain data encoding?\n",
        "\n",
        "- Converting categorical data into numerical format for ML models.\n",
        "Techniques: One-Hot, Label Encoding, Ordinal Encoding."
      ]
    }
  ]
}